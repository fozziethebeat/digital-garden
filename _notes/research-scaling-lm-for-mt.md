---
title: "Examining Scaling and Transfer of Language Model Architectures for Machine Translation"
excerpt: Language Models can transfer learn to Machine Translation when done right
---

This [[Research]] [paper](https://arxiv.org/pdf/2202.00528.pdf) compares how
Large Language Models can or can not be applied towards Machine Translation in
contrast to traditional Encoder Decoder models.

Main Conclusions:

-  Encoder Decoder models still out perform Language Models.
-  Prefix based LMs that are deep and make the full source visible do better
   than other LM variants and are comparable to Encoder Decoder models.
